{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit ADHD Women Message Board Comments: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADHD Reddit Women\n",
    "import pandas as pd\n",
    "adhdw = pd.read_csv(r'C:\\Career\\LighthouseLabs\\Final Project\\Potential Datasets\\ADHD Reddit\\adhdwomen-comment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202658, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adhdw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2480      Like, outside of context you may be right. But...\n",
      "20617     Actually lots of folks failed at college becau...\n",
      "20720     I did full psycho educational testing as part ...\n",
      "52103     There are people way more fucked up in the hea...\n",
      "52129     That psychiatrist is full of shit. I'm so sorr...\n",
      "                                ...                        \n",
      "202236    I have a very sensitive gag reflex, so my spou...\n",
      "202255    I bought a magnetic whiteboard for the front o...\n",
      "202265    I read somewhere that if plastic containers ha...\n",
      "202632    The book is called\\n\\n\\n You Mean I'm Not Lazy...\n",
      "202646    Ugh, I have the other part - where the 'gifted...\n",
      "Name: body, Length: 338, dtype: object\n"
     ]
    }
   ],
   "source": [
    "high_scoresw_50 = adhdw.loc[adhdw['score'] > 50, 'body']\n",
    "print(high_scoresw_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_scoresw_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54025     Every time I read something like this I think ...\n",
      "54497     I got that from a guy who goes to Burning Man ...\n",
      "55239     I used to read fiction books in school-I would...\n",
      "55309     &gt;\"because you were able to complete a Maste...\n",
      "56445     honestly, can text messages get a 'remind me' ...\n",
      "                                ...                        \n",
      "169448    This was a MAJOR realization of mine recently ...\n",
      "200892    Sounds like it could be sensory overload? Ther...\n",
      "200939    Oooh I find the opposite! If I can feel my und...\n",
      "201007    The biggest lie we tell ourselves is, \"I will ...\n",
      "202646    Ugh, I have the other part - where the 'gifted...\n",
      "Name: body, Length: 101, dtype: object\n"
     ]
    }
   ],
   "source": [
    "high_scoresw_100 = adhdw.loc[adhdw['score'] > 100, 'body']\n",
    "print(high_scoresw_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_scoresw_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56445     honestly, can text messages get a 'remind me' ...\n",
      "76082     Without electronic stimulation or diversion I ...\n",
      "77363     *avoid entire rooms in my house for days at a ...\n",
      "77715     Yup. I work as a cashier. Imagine the pain of ...\n",
      "79163     Woah. I didnâ€™t realize thatâ€™s why I did that ðŸ¤¯...\n",
      "108255    every single day. i think it is because iâ€™m ov...\n",
      "109156    This is a very real thing! ADHD coaches recomm...\n",
      "109756    I would heavily follow the \"treat others the w...\n",
      "110944    Umm...How did I never know I needed this until...\n",
      "111579    This is why I hate all these scenarios where I...\n",
      "128129    So my psychologist explained that some people ...\n",
      "128598    Binge eating as a means of dopamine seeking is...\n",
      "140715    Are you bloody joking me? Normal people can re...\n",
      "140727    My neurotypical partner says no, so Iâ€™m really...\n",
      "142189    Thank you. This was almost too real to read, b...\n",
      "142208    I hear about too many highly intelligent peopl...\n",
      "143341    Also we have some kind of memory glitch where ...\n",
      "143775    They forgot regret. Outrage when you find out ...\n",
      "146611    Lol I didn't know other people did this. I pro...\n",
      "148091    The self awareness is probably the hardest sym...\n",
      "151688    yup. \\n\\nand be proud of that ACT score, not a...\n",
      "151726    Hey it's me! I won an award for having one of ...\n",
      "152463    I am SO guilty of this. After reading a book o...\n",
      "153195    Good job! You are only blessing yourself each ...\n",
      "154488    They're using it to work 12 hours straight, me...\n",
      "154532    This so so so much. \\n\\nAdderall kicks in, nap...\n",
      "154559              Me on stims: \"look ma, I put pants on!\"\n",
      "154629    i've been diagnosed for over a year now, and i...\n",
      "154659                  Iâ€™ve taken it and fallen asleep too\n",
      "155029    I think it's called sleep revenge. You spend a...\n",
      "155346    I set an alarm before bed with the label â€œSOUP...\n",
      "166445    I feel this so much. My sink is full. My laund...\n",
      "167307    Forced prioritizing! I also thrive best when m...\n",
      "168300    ðŸ˜­\\n\\nI don't know who you are but you've descr...\n",
      "168304    Ok but seriously, that asshole Duolingo owl is...\n",
      "168317    Iâ€™m finally speaking to my GP tomorrow about p...\n",
      "168341    ADHD is wanting to reply to comments and relat...\n",
      "169360    This resonated with me a lot.\\n\\nI've always b...\n",
      "169413    &gt; \\n&gt; \\n&gt; \\n&gt; \\n&gt; And then I ca...\n",
      "169448    This was a MAJOR realization of mine recently ...\n",
      "200939    Oooh I find the opposite! If I can feel my und...\n",
      "201007    The biggest lie we tell ourselves is, \"I will ...\n",
      "202646    Ugh, I have the other part - where the 'gifted...\n",
      "Name: body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "high_scoresw_150 = adhdw.loc[adhdw['score'] > 150, 'body']\n",
    "print(high_scoresw_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_scoresw_150.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76082     Without electronic stimulation or diversion I ...\n",
      "77363     *avoid entire rooms in my house for days at a ...\n",
      "79163     Woah. I didnâ€™t realize thatâ€™s why I did that ðŸ¤¯...\n",
      "128598    Binge eating as a means of dopamine seeking is...\n",
      "140715    Are you bloody joking me? Normal people can re...\n",
      "140727    My neurotypical partner says no, so Iâ€™m really...\n",
      "143341    Also we have some kind of memory glitch where ...\n",
      "143775    They forgot regret. Outrage when you find out ...\n",
      "146611    Lol I didn't know other people did this. I pro...\n",
      "148091    The self awareness is probably the hardest sym...\n",
      "153195    Good job! You are only blessing yourself each ...\n",
      "154488    They're using it to work 12 hours straight, me...\n",
      "154532    This so so so much. \\n\\nAdderall kicks in, nap...\n",
      "155029    I think it's called sleep revenge. You spend a...\n",
      "167307    Forced prioritizing! I also thrive best when m...\n",
      "168300    ðŸ˜­\\n\\nI don't know who you are but you've descr...\n",
      "168304    Ok but seriously, that asshole Duolingo owl is...\n",
      "169360    This resonated with me a lot.\\n\\nI've always b...\n",
      "169413    &gt; \\n&gt; \\n&gt; \\n&gt; \\n&gt; And then I ca...\n",
      "169448    This was a MAJOR realization of mine recently ...\n",
      "Name: body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "high_scoresw_200 = adhdw.loc[adhdw['score'] > 200, 'body']\n",
    "print(high_scoresw_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_scoresw_200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54974                                             [removed]\n",
      "56620     can you send some pics? Nude? Just fpr researc...\n",
      "62255                                        #Don't take it\n",
      "74504     As someone who is diagnosed with \"severe adult...\n",
      "84285     So am I going to get banned from this sub too ...\n",
      "84308     Iâ€™m comfortable voting as I plan to. Just wond...\n",
      "84401     If you don't want kids then don't have unprote...\n",
      "109733                                            [removed]\n",
      "111657    Not a woman and don't have ADHD (front page al...\n",
      "144453    This is r/adhdwomen so you can probably just u...\n",
      "144462    NBs arenâ€™t women and most women just go by she...\n",
      "144479    I may not be NB, but I am a privileged white g...\n",
      "149681    You can't change a sleep pattern by going to b...\n",
      "150057    Well, I don't know that you can write a post t...\n",
      "152099                                                   No\n",
      "155458    Thank you, but for the questionably homophobic...\n",
      "198857    Less pretending, and more work, might actually...\n",
      "Name: body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Low Scores (downvoted) Women\n",
    "low_scoresw_neg8 = adhdw.loc[adhdw['score'] < -8, 'body']\n",
    "print(low_scoresw_neg8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_scoresw_neg8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n",
      "-19\n"
     ]
    }
   ],
   "source": [
    "print(adhdw['body'][152099])\n",
    "print(adhdw['score'][152099])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER Sentiment Analysis with Sentiment Intensity Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already Done or Unneeded Steps from Google Colab analysis\n",
    "# # Import data before pre-processing\n",
    "# dfw = pd.read_csv('adhdwomen-comment.csv')\n",
    "# dfw = pd.read_csv('adhdwomen-comment.csv', encoding='utf-8')\n",
    "# # Google Colab necessity\n",
    "# !pip install nltk  # Install nltk if not already installed\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare your text data\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More Google Colab necessity\n",
    "# !pip install nltk  # Install nltk if not already installed\n",
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Tokenize your text\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stop_words and token.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "adhdw['tokens'] = adhdw['body'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train a Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=adhdw['tokens'], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate word embeddings\n",
    "def generate_word_embeddings(tokens):\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in word2vec_model.wv.key_to_index:\n",
    "            embeddings.append(word2vec_model.wv[word2vec_model.wv.key_to_index[token]])\n",
    "    return embeddings\n",
    "\n",
    "adhdw['embeddings'] = adhdw['tokens'].apply(generate_word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Aggregate the word embeddings\n",
    "def aggregate_embeddings(embeddings):\n",
    "    if len(embeddings) > 0:\n",
    "        aggregated_embedding = sum(embeddings) / len(embeddings)\n",
    "    else:\n",
    "        aggregated_embedding = []\n",
    "    return aggregated_embedding\n",
    "\n",
    "adhdw['aggregated_embedding'] = adhdw['embeddings'].apply(aggregate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time for VADER\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Apply sentiment analysis using VADER Intensity Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment(embedding):\n",
    "    embedding_str = [str(item) for item in embedding]\n",
    "    sentiment_scores = analyzer.polarity_scores(\" \".join(embedding_str))\n",
    "    return sentiment_scores\n",
    "\n",
    "adhdw['sentiment_scores'] = adhdw['tokens'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         {'neg': 0.132, 'neu': 0.575, 'pos': 0.293, 'co...\n",
      "1         {'neg': 0.118, 'neu': 0.743, 'pos': 0.139, 'co...\n",
      "2         {'neg': 0.169, 'neu': 0.637, 'pos': 0.195, 'co...\n",
      "3         {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
      "4         {'neg': 0.023, 'neu': 0.788, 'pos': 0.188, 'co...\n",
      "                                ...                        \n",
      "202653    {'neg': 0.0, 'neu': 0.39, 'pos': 0.61, 'compou...\n",
      "202654    {'neg': 0.0, 'neu': 0.648, 'pos': 0.352, 'comp...\n",
      "202655    {'neg': 0.264, 'neu': 0.536, 'pos': 0.2, 'comp...\n",
      "202656    {'neg': 0.185, 'neu': 0.645, 'pos': 0.169, 'co...\n",
      "202657    {'neg': 0.0, 'neu': 0.86, 'pos': 0.14, 'compou...\n",
      "Name: sentiment_scores, Length: 202658, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(adhdw['sentiment_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative score: 0.169\n",
      "Neutral score: 0.443\n",
      "Positive score: 0.388\n",
      "Compound score: 0.8126\n",
      "Forced prioritizing! I also thrive best when my choices are made for me. Not trying to be smart, that's literally how it is. Learning to appropriate prioritize stuff is the one skill I feel like I could probably improve rather than accept I'm just bad at.\n"
     ]
    }
   ],
   "source": [
    "# Accessing sentiment scores for 167307 document, a Top 20 highest score\n",
    "scores = adhdw['sentiment_scores'][167307]\n",
    "negative_score = scores['neg']\n",
    "neutral_score = scores['neu']\n",
    "positive_score = scores['pos']\n",
    "compound_score = scores['compound']\n",
    "\n",
    "# Printing the scores\n",
    "print(\"Negative score:\", negative_score)\n",
    "print(\"Neutral score:\", neutral_score)\n",
    "print(\"Positive score:\", positive_score)\n",
    "print(\"Compound score:\", compound_score)\n",
    "print(adhdw['body'][167307])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative score: 0.059\n",
      "Neutral score: 0.523\n",
      "Positive score: 0.418\n",
      "Compound score: 0.8836\n",
      "Good job! You are only blessing yourself each time you brush. I am so happy you are making this a priority. Most ADHD medications are really hard on the mouth, so you are even helping yourself out even more so. \n",
      "\n",
      "Signed,\n",
      "Dental Professional With ADHD\n"
     ]
    }
   ],
   "source": [
    "# Accessing sentiment scores for 153195 document, a Top 20 highest score\n",
    "scores = adhdw['sentiment_scores'][153195]\n",
    "negative_score = scores['neg']\n",
    "neutral_score = scores['neu']\n",
    "positive_score = scores['pos']\n",
    "compound_score = scores['compound']\n",
    "\n",
    "# Printing the scores\n",
    "print(\"Negative score:\", negative_score)\n",
    "print(\"Neutral score:\", neutral_score)\n",
    "print(\"Positive score:\", positive_score)\n",
    "print(\"Compound score:\", compound_score)\n",
    "print(adhdw['body'][153195])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative score: 0.0\n",
      "Neutral score: 0.0\n",
      "Positive score: 0.0\n",
      "Compound score: 0.0\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "# Accessing sentiment scores for 152099 document, a Top 20 downvotes (-19) score\n",
    "scores = adhdw['sentiment_scores'][152099]\n",
    "negative_score = scores['neg']\n",
    "neutral_score = scores['neu']\n",
    "positive_score = scores['pos']\n",
    "compound_score = scores['compound']\n",
    "\n",
    "# Printing the scores\n",
    "print(\"Negative score:\", negative_score)\n",
    "print(\"Neutral score:\", neutral_score)\n",
    "print(\"Positive score:\", positive_score)\n",
    "print(\"Compound score:\", compound_score)\n",
    "print(adhdw['body'][152099])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative score: 0.0\n",
      "Neutral score: 1.0\n",
      "Positive score: 0.0\n",
      "Compound score: 0.0\n",
      "can you send some pics? Nude? Just fpr research purposses\n",
      "Downvotes: -18\n"
     ]
    }
   ],
   "source": [
    "# Accessing sentiment scores for 56620 document, a Top 20 downvotes (-18) score\n",
    "scores = adhdw['sentiment_scores'][56620]\n",
    "negative_score = scores['neg']\n",
    "neutral_score = scores['neu']\n",
    "positive_score = scores['pos']\n",
    "compound_score = scores['compound']\n",
    "\n",
    "# Printing the scores\n",
    "print(\"Negative score:\", negative_score)\n",
    "print(\"Neutral score:\", neutral_score)\n",
    "print(\"Positive score:\", positive_score)\n",
    "print(\"Compound score:\", compound_score)\n",
    "print(adhdw['body'][56620])\n",
    "print(\"Downvotes:\", adhdw['score'][56620])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative score: 0.0\n",
      "Neutral score: 0.568\n",
      "Positive score: 0.432\n",
      "Compound score: 0.4228\n",
      "Less pretending, and more work, might actually help your life.\n",
      "Downvotes: -13\n"
     ]
    }
   ],
   "source": [
    "# Accessing sentiment scores for 198857 document, a Top 20 downvotes (-13) score\n",
    "scores = adhdw['sentiment_scores'][198857]\n",
    "negative_score = scores['neg']\n",
    "neutral_score = scores['neu']\n",
    "positive_score = scores['pos']\n",
    "compound_score = scores['compound']\n",
    "\n",
    "# Printing the scores\n",
    "print(\"Negative score:\", negative_score)\n",
    "print(\"Neutral score:\", neutral_score)\n",
    "print(\"Positive score:\", positive_score)\n",
    "print(\"Compound score:\", compound_score)\n",
    "print(adhdw['body'][198857])\n",
    "print(\"Downvotes:\", adhdw['score'][198857])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative score: 0.3\n",
      "Neutral score: 0.7\n",
      "Positive score: 0.0\n",
      "Compound score: -0.4588\n",
      "So am I going to get banned from this sub too for saying Iâ€™m going to vote Trump?\n",
      "Downvotes: -16\n"
     ]
    }
   ],
   "source": [
    "# Accessing sentiment scores for 84285 document, a Top 20 downvotes (-16) score\n",
    "scores = adhdw['sentiment_scores'][84285]\n",
    "negative_score = scores['neg']\n",
    "neutral_score = scores['neu']\n",
    "positive_score = scores['pos']\n",
    "compound_score = scores['compound']\n",
    "\n",
    "# Printing the scores\n",
    "print(\"Negative score:\", negative_score)\n",
    "print(\"Neutral score:\", neutral_score)\n",
    "print(\"Positive score:\", positive_score)\n",
    "print(\"Compound score:\", compound_score)\n",
    "print(adhdw['body'][84285])\n",
    "print(\"Downvotes:\", adhdw['score'][84285])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Negative Score: 0.10907867441699917\n",
      "Average Neutral Score: 0.6150517127376681\n",
      "Average Positive Score: 0.2676934934717366\n",
      "Average Compound Score: 0.32248199478922424\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store cumulative scores\n",
    "total_negative = 0\n",
    "total_neutral = 0\n",
    "total_positive = 0\n",
    "total_compound = 0\n",
    "num_documents = len(adhdw)\n",
    "\n",
    "# Iterate over the sentiment scores and accumulate the scores\n",
    "for scores_dict in adhdw['sentiment_scores']:\n",
    "    total_negative += scores_dict['neg']\n",
    "    total_neutral += scores_dict['neu']\n",
    "    total_positive += scores_dict['pos']\n",
    "    total_compound += scores_dict['compound']\n",
    "\n",
    "# Calculate the average scores\n",
    "average_negative = total_negative / num_documents\n",
    "average_neutral = total_neutral / num_documents\n",
    "average_positive = total_positive / num_documents\n",
    "average_compound = total_compound / num_documents\n",
    "\n",
    "# Print the average scores\n",
    "print(\"Average Negative Score:\", average_negative)\n",
    "print(\"Average Neutral Score:\", average_neutral)\n",
    "print(\"Average Positive Score:\", average_positive)\n",
    "print('Average Compound Score:', average_compound )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Negative Score: 0.10907867441699917\n",
    "\n",
    "Average Neutral Score: 0.6150517127376681\n",
    "\n",
    "Average Positive Score: 0.2676934934717366\n",
    "\n",
    "Average Compound Score: 0.32248199478922424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thisone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
